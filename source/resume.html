<!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>Professional Experience</title>
            <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only],
.vscode-high-contrast:not(.vscode-high-contrast-light) img[src$=\#gh-light-mode-only],
.vscode-high-contrast-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

</style>
            
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
<style>
:root {
  --color-note: #0969da;
  --color-tip: #1a7f37;
  --color-warning: #9a6700;
  --color-severe: #bc4c00;
  --color-caution: #d1242f;
  --color-important: #8250df;
}

</style>
<style>
@media (prefers-color-scheme: dark) {
  :root {
    --color-note: #2f81f7;
    --color-tip: #3fb950;
    --color-warning: #d29922;
    --color-severe: #db6d28;
    --color-caution: #f85149;
    --color-important: #a371f7;
  }
}

</style>
<style>
.markdown-alert {
  padding: 0.5rem 1rem;
  margin-bottom: 16px;
  color: inherit;
  border-left: .25em solid #888;
}

.markdown-alert>:first-child {
  margin-top: 0
}

.markdown-alert>:last-child {
  margin-bottom: 0
}

.markdown-alert .markdown-alert-title {
  display: flex;
  font-weight: 500;
  align-items: center;
  line-height: 1
}

.markdown-alert .markdown-alert-title .octicon {
  margin-right: 0.5rem;
  display: inline-block;
  overflow: visible !important;
  vertical-align: text-bottom;
  fill: currentColor;
}

.markdown-alert.markdown-alert-note {
  border-left-color: var(--color-note);
}

.markdown-alert.markdown-alert-note .markdown-alert-title {
  color: var(--color-note);
}

.markdown-alert.markdown-alert-important {
  border-left-color: var(--color-important);
}

.markdown-alert.markdown-alert-important .markdown-alert-title {
  color: var(--color-important);
}

.markdown-alert.markdown-alert-warning {
  border-left-color: var(--color-warning);
}

.markdown-alert.markdown-alert-warning .markdown-alert-title {
  color: var(--color-warning);
}

.markdown-alert.markdown-alert-tip {
  border-left-color: var(--color-tip);
}

.markdown-alert.markdown-alert-tip .markdown-alert-title {
  color: var(--color-tip);
}

.markdown-alert.markdown-alert-caution {
  border-left-color: var(--color-caution);
}

.markdown-alert.markdown-alert-caution .markdown-alert-title {
  color: var(--color-caution);
}

</style>
        
        </head>
        <body class="vscode-body vscode-light">
            <link rel="stylesheet" type="text/css" href="resume.css">
<p><span class="name">Dongyoon Wee</span></p>
<span class="info">
<p><a href="mailto:dongyoon.wee@gmail.com"><img src="https://simpleicons.org/icons/minutemailer.svg" alt="Mail"> dongyoon.wee@gmail.com</a>
<a href="https://github.com/dongyoon-wee"><img src="https://simpleicons.org/icons/github.svg" alt="GitHub"> github.com/dongyoon-wee</a></p>
</span>
<h2 id="professional-experience">Professional Experience</h2>
<h3 id="leader-video-ai-research--naver--jun-2020--present-">Leader Video AI Research | <a href="https://www.naver.com/">Naver</a> <time> Jun 2020 – Present </time></h3>
<ul>
<li>Led research on video representation, 3D scene reconstruction, multi-instance tracking</li>
<li>Led to build MLOps system for efficient ML model training &amp; serving</li>
<li>Establish academic collaboration and set a publication strategy</li>
<li>Led development of video analysis system, face edit system, videoQA system</li>
</ul>
<h3 id="tech-lead-video-ai-research--naver--dec-2017--jun-2020-">Tech Lead Video AI Research | <a href="https://www.naver.com/">Naver</a> <time> Dec 2017 – Jun 2020 </time></h3>
<ul>
<li>Led research on action recognition, tracking ML model</li>
<li>Developed video theme classification ML system for video recommendation</li>
<li>Developed people tracking ML system for AutoHighlight system</li>
</ul>
<h3 id="machine-learning-engineer--buzzvil--mar-2017--dec-2017-">Machine Learning Engineer | <a href="https://www.buzzvil.com/en">Buzzvil</a> <time> Mar 2017 – Dec 2017 </time></h3>
<ul>
<li>Developed news recommendation system based on ML model</li>
<li>Developed data pipeline system to train/infer ML model</li>
</ul>
<h3 id="data-scientist--lg-cns--jan-2015--mar-2017-">Data Scientist | <a href="https://www.lgcns.com/">LG CNS</a> <time> Jan 2015 – Mar 2017 </time></h3>
<ul>
<li>Developed defect inspection ML model for manufacturing industry</li>
<li>Developed image search ML model for retail industry</li>
<li>Developed fraud detection ML model for financial industry</li>
<li>Developed churn prediction ML model for telecom industry</li>
</ul>
<h3 id="associate-research-engineer--ls-cable--dec-2010--nov-2014-">Associate Research Engineer | <a href="https://www.lscns.co.kr/kr/main.asp">LS Cable</a> <time> Dec 2010 – Nov 2014 </time></h3>
<ul>
<li>Developed cable performance prediction system</li>
<li>Developed power grid monitoring system under IEC 61850</li>
<li>Developed remote monitoring system for wind/solar power generation</li>
</ul>
<h3 id="research-intern--edf-rd--mar-2010--sep-2010-">Research Intern | <a href="https://www.edf.fr/en">EDF R&amp;D</a> <time> Mar 2010 – Sep 2010 </time></h3>
<ul>
<li>Implemented EOLSR(Energy Efficient Routing Protocol) in TinyOS for OCARI project</li>
<li>Simulated the implemented network and proved its efficiency</li>
</ul>
<h3 id="research-intern--lg-electronics--may-2009--sep-2009-">Research Intern | <a href="https://www.lge.co.kr/">LG Electronics</a> <time> May 2009 – Sep 2009 </time></h3>
<ul>
<li>Developed widget program for mobile phone</li>
</ul>
<h2 id="education">Education</h2>
<h3 id="masters-degree-seoul-national-university---electrical-engineering---mar-2008--feb-2011-">Master's degree, Seoul National University | <location> Electrical Engineering </location> <time> Mar 2008 – Feb 2011 </time></h3>
<ul>
<li>Dual master's degree on Ecole des Mines de Saint-Etienne</li>
<li>Thesis on &quot;Implementation EOLSR in TinyOS&quot; based on wireless network protocol and simulation</li>
</ul>
<h3 id="masters-degree-ecole-des-mines-de-saint-etienne---computer-science---sep-2008--aug-2010-">Master's degree, Ecole des Mines de Saint-Etienne | <location> Computer Science </location> <time> Sep 2008 – Aug 2010 </time></h3>
<h3 id="bachelors-degree-seoul-nation-university---electrical-engineering---mar-2003--aug-2008-">Bachelor's Degree, Seoul Nation University | <location> Electrical Engineering </location> <time> Mar 2003 – Aug 2008 </time></h3>
<h2 id="fellowships--awards">Fellowships &amp; Awards</h2>
<h3 id="n-innovation-3rd-place--naver--jan-2024-">N-Innovation 3rd place | <a href="https://www.naver.com/">Naver</a> <time> Jan 2024 </time></h3>
<ul>
<li>Developed short-form generation system for ShoppingLive service</li>
</ul>
<h3 id="n-innovation-1st-place--naver--dec-2018-">N-Innovation 1st place | <a href="https://www.naver.com/">Naver</a> <time> Dec 2018 </time></h3>
<ul>
<li>Developed people tracking system for AutoHighlight service</li>
</ul>
<h3 id="hackathon-1st-place--lg-cns--oct-2016-">Hackathon 1st place | <a href="https://www.lgcns.com/">LG CNS</a> <time> Oct 2016 </time></h3>
<ul>
<li>Developed object detection module on Jetson TX2 for self-driving car</li>
</ul>
<h3 id="blaise-pascal-scholarship--government-of-france--jul-2008-">Blaise Pascal Scholarship | Government of France <time> Jul 2008 </time></h3>
<ul>
<li>Bourses d'excellence Blaise Pascal (acceptance rate: 4%)</li>
</ul>
<h2 id="publications">Publications</h2>
<p>Kim, Jaehyeok, Wee, D., &amp; Xu, D. (2023). You Only Train Once: Multi-Identity Free-Viewpoint Neural Human Rendering from Monocular Videos. arXiv Preprint arXiv:2303. 05835.</p>
<p>Lee, P., Kim, T., Shim, M., Wee, D., &amp; Byun, H. (2023). Decomposed cross-modal distillation for rgb-based temporal action detection. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2373–2383.</p>
<p>Shim, M., Kim, T., Kim, J., &amp; Wee, D. (2023). Masked Autoencoder for Unsupervised Video Summarization. arXiv Preprint arXiv:2306. 01395.</p>
<p>Kim, Jinhyung, Kim, T., Shim, M., Han, D., Wee, D., &amp; Kim, J. (2023). Frequency selective augmentation for video representation learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37, 1124–1132.</p>
<p>Yang, C., Kong, K., Min, S., Wee, D., Jang, H.-D., Cha, G., &amp; Kang, S. (2023). Sefd: learning to distill complex pose and occlusion. Proceedings of the IEEE/CVF International Conference on Computer Vision, 14941–14952.</p>
<p>Hyun, J., Kang, M., Wee, D., &amp; Yeung, D.-Y. (2023). Detection recovery in online multi-object tracking with sparse graph tracker. Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 4850–4859.</p>
<p>Kim, T., Kim, J., Shim, M., Yun, S., Kang, M., Wee, D., &amp; Lee, S. (2022). Exploring temporally dynamic data augmentation for video recognition. arXiv Preprint arXiv:2206. 15015.</p>
<p>Cha, G., Jang, H.-D., &amp; Wee, D. (2022). Self-Supervised Depth Estimation with Isometric-Self-Sample-Based Learning. arXiv Preprint arXiv:2205. 10006.</p>
<p>Cha, G., Shin, C., Yoon, S., &amp; Wee, D. (2022). Out of Sight, Out of Mind: A Source-View-Wise Feature Aggregation for Multi-View Image-Based Rendering. arXiv Preprint arXiv:2206. 04906.</p>
<p>Kim, Jinhyung, Kim, T., Shim, M., Han, D., Wee, D., &amp; Kim, J. (2022). Spatiotemporal augmentation on selective frequencies for video representation learning. arXiv Preprint arXiv:2204. 03865, 3.</p>
<p>Monet, N., &amp; Wee, D. (2022). MEEV: Body Mesh Estimation On Egocentric Video. arXiv Preprint arXiv:2210. 14165.</p>
<p>Lee, I., Kim, D., Wee, D., &amp; Lee, S. (2021). An efficient human instance-guided framework for video action recognition. Sensors, 21(24), 8309.</p>
<p>Shim, M., Ho, H.-I., Kim, J., &amp; Wee, D. (2020). Read: Reciprocal attention discriminator for image-to-video re-identification. European Conference on Computer Vision, 335–350. Springer International Publishing Cham.</p>
<p>Kim, Jinhyung, Cha, S., Wee, D., Bae, S., &amp; Kim, J. (2020). Regularization on spatio-temporally smoothed feature for action recognition. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 12103–12112.</p>
<p>Ho, H.-I., Shim, M., &amp; Wee, D. (2020). Learning from dances: pose-invariant re-identification for multi-person tracking. ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2113–2117. IEEE.</p>

            
            
        </body>
        </html>